# ЛР3
## Теоретическая база  
В данной работе было произведено сравнение двух сверточных нейронных сетей EfficientNetv2 и ResNetv2 с визуальным трансформером ViT.
Все модели были обучены на датасете ImageNet21K, который содержит 14 миллионов изображений, классифицированных в 21,841 категорий.
Размер входного изображения: 224x224 пикселей.

### Vision Transformer
<img src="https://theaisummer.com/static/60c2cbe8edb845502c8bbc3b9e88791d/ee604/vision-transformer.png" width=70% height=70%>  

Vision Transformer представляет собой альтернативу классическим сверточным нейронным сетям для обработки изображений.
ViT использует подход, называемый "подача последовательности", где изображение разбивается на патчи фиксированного размера, а затем каждый патч кодируется вектором признаков, как входная последовательность для трансформера. Поскольку трансформеры были изначально разработаны для обработки последовательностей, а не изображений, в ViT используется специальный тип трансформеров, называемый "трансформер с вниманием к изображению" (image-attention transformer), который учитывает пространственную структуру патчей и их отношения в изображении.

В работе была использована модель vit_base_patch16_224_in21k [1]:
- Разбиение изображения на квадраты размером 16x16 пикселей для последующей обработки
- Количество слоев: 12
- Архитектура: Transformer с использованием визуальных патчей (patch-based) и Positional Embeddings
- Оптимизация: Stochastic Gradient Descent (SGD) с моментом

### CNN
Convolutional Neural Network (Сверточная нейронная сеть) является классом нейронных сетей, специализированных на анализе изображений и видео. CNN были разработаны для обработки данных сеточной структуры, таких как изображения.

Основным элементом CNN является сверточный слой (convolutional layer), который обрабатывает входные данные через свертку с фильтрами (ядрами). Свертка позволяет выделить важные признаки изображения, такие как границы, формы, текстуры и т.д. Следующим шагом обычно является применение слоя пулинга (pooling layer), который уменьшает размерность изображения, сохраняя важные признаки. Затем полученные признаки подаются на полносвязный слой (fully-connected layer), который выполняет классификацию.

#### EfficientNetv2
<img src="https://miro.medium.com/max/1204/1*DOf_v9EJuOhldHugkB8dAA.png" width=50% height=50%> 
Модели EfficientNetv2 оптимизированы для работы на мобильных и встроенных устройствах, где вычислительные ресурсы ограничены. Они используют алгоритмы автоматической масштабирования, которые позволяют оптимизировать модель по трём основным аспектам: глубине (depth), ширине (width) и разрешению изображения (resolution).

В работе была использована модель tf_efficientnetv2_m_in21k [2]:
- Количество слоев: 21
- Архитектура: Mobile Inverted Residual Bottleneck (MBConv) с Squeeze-and-Excitation (SE) блоками и Swish активациями
- Оптимизация: AutoAugment, Mixup, Label Smoothing, Cosine Annealing, Cutout

#### ResNetv2
<img src="https://static.packt-cdn.com/products/9781788629416/graphics/B08956_02_10.jpg" width=40% height=40%>  
ResNetv2 - модификация архитектуры ResNet. Она включает блоки Residual и Bottleneck, которые позволяют модели обучаться глубже, минимизируя проблему затухающего градиента. Блоки Bottleneck позволяют сократить количество параметров модели, что уменьшает вычислительную сложность

В работе была использована модель resnetv2_50x1_bitm_in21k [3]:
- Количество слоев: 50
- Архитектура: ResNetv2, использующая блоки Residual и Bottleneck
- Оптимизация: Stochastic Gradient Descent (SGD) с моментом

## Описание разработанной системы

В датасете содержится 10 классов, разбитых по папкам, по 5 изображений в каждой. В файле imagenet21k_wordnet_lemmas.txt содержатся названия всех классов изображений.
Программа загружает модели с предварительно обученными весами. При считывании каждое изображение из папки класса предобрабатывается. На выходе модели после применения softmax получаются вероятности принадлежности к классам, по которым высчитываются top 1 и top 5 accuracy.

## Результаты  

| model                      | acc_1 | acc_5 | Memory usage (torch+model), MB | time, s |
|----------------------------|-------|-------|--------------------------------|---------|
| ViT                        | 0.6   | 0.88  | 1073                           | 3.75    | 
| EfficientNetv2             | 0.6   | 0.84  | 959                            | 2.74    |
| ResNetv2                   | 0.6   | 0.9   | 917                            | 2.62    |

## Выводы 
Эксперименты показали, что Resnetv2 обладает наибольшей точностью, занимает меньше всего памяти и находится на первом месте по скорости работы. 

## Использованные источники
[1] https://arxiv.org/abs/2010.11929  
[2] https://arxiv.org/abs/2104.00298  
[3] https://arxiv.org/abs/1912.11370  
